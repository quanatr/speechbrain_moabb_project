{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SpeechBrain-MOABB benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/speechbrain/benchmarks\n",
    "%cd benchmarks\n",
    "!git checkout eeg\n",
    "\n",
    "%cd benchmarks/benchmarks/MOABB\n",
    "%pip install -r extra-requirements.txt # Install additional dependencies\n",
    "\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Clone SpeechBrain repository (development branch)\n",
    "!git clone https://github.com/speechbrain/speechbrain/\n",
    "%cd speechbrain/\n",
    "\n",
    "# Install required dependencies\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "# Install SpeechBrain in editable mode\n",
    "%pip install -e .\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mne moabb orion scikit-learn torch torchinfo\n",
    "\n",
    "import mne\n",
    "import moabb\n",
    "import orion\n",
    "import sklearn\n",
    "import torch\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: hyperpyyaml in /home/aquan/.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aquan/.local/lib/python3.10/site-packages (from hyperpyyaml) (6.0.1)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /home/aquan/.local/lib/python3.10/site-packages (from hyperpyyaml) (0.18.6)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/aquan/.local/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml) (0.2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hyperpyyaml\n",
    "from hyperpyyaml import load_hyperpyyaml, dump_hyperpyyaml\n",
    "\n",
    "example_hyperparams = \"\"\"\n",
    "seed: 1234\n",
    "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
    "\n",
    "# DIRECTORIES\n",
    "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
    "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
    "output_folder: !PLACEHOLDER #'path/to/results'\n",
    "\n",
    "# DATASET HPARS\n",
    "# Defining the MOABB dataset.\n",
    "dataset: !new:moabb.datasets.BNCI2014001\n",
    "save_prepared_dataset: True # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards\n",
    "data_iterator_name: !PLACEHOLDER\n",
    "target_subject_idx: !PLACEHOLDER\n",
    "target_session_idx: !PLACEHOLDER\n",
    "events_to_load: null # all events will be loaded\n",
    "original_sample_rate: 250 # Original sampling rate provided by dataset authors\n",
    "sample_rate: 125 # Target sampling rate (Hz)\n",
    "# band-pass filtering cut-off frequencies\n",
    "fmin: 0.13 # @orion_step1: --fmin~\"uniform(0.1, 5, precision=2)\"\n",
    "fmax: 46.0 # @orion_step1: --fmax~\"uniform(20.0, 50.0, precision=3)\"\n",
    "n_classes: 4\n",
    "# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class\n",
    "# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long\n",
    "# dataset interval starts from 2\n",
    "# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)\n",
    "tmin: 0.\n",
    "tmax: 4.0 # @orion_step1: --tmax~\"uniform(1.0, 4.0, precision=2)\"\n",
    "# number of steps used when selecting adjacent channels from a seed channel (default at Cz)\n",
    "n_steps_channel_selection: 2 # @orion_step1: --n_steps_channel_selection~\"uniform(1, 3,discrete=True)\"\n",
    "T: !apply:math.ceil\n",
    "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
    "C: 22\n",
    "# We here specify how to perfom test:\n",
    "# - If test_with: 'last' we perform test with the latest model.\n",
    "# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)\n",
    "# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.\n",
    "# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.\n",
    "test_with: 'last' # 'last' or 'best'\n",
    "test_key: \"acc\" # Possible opts: \"loss\", \"f1\", \"auc\", \"acc\"\n",
    "\n",
    "# METRICS\n",
    "f1: !name:sklearn.metrics.f1_score\n",
    "    average: 'macro'\n",
    "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
    "cm: !name:sklearn.metrics.confusion_matrix\n",
    "metrics:\n",
    "    f1: !ref <f1>\n",
    "    acc: !ref <acc>\n",
    "    cm: !ref <cm>\n",
    "# TRAINING HPARS\n",
    "n_train_examples: 100  # it will be replaced in the train script\n",
    "# checkpoints to average\n",
    "avg_models: 10 # @orion_step1: --avg_models~\"uniform(1, 15,discrete=True)\"\n",
    "number_of_epochs: 862 # @orion_step1: --number_of_epochs~\"uniform(250, 1000, discrete=True)\"\n",
    "lr: 0.0001 # @orion_step1: --lr~\"choices([0.01, 0.005, 0.001, 0.0005, 0.0001])\"\n",
    "# Learning rate scheduling (cyclic learning rate is used here)\n",
    "max_lr: !ref <lr> # Upper bound of the cycle (max value of the lr)\n",
    "base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)\n",
    "step_size_multiplier: 5 #from 2 to 8\n",
    "step_size: !apply:round\n",
    "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
    "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
    "    base_lr: !ref <base_lr>\n",
    "    max_lr: !ref <max_lr>\n",
    "    step_size: !ref <step_size>\n",
    "label_smoothing: 0.0\n",
    "loss: !name:speechbrain.nnet.losses.nll_loss\n",
    "    label_smoothing: !ref <label_smoothing>\n",
    "optimizer: !name:torch.optim.Adam\n",
    "    lr: !ref <lr>\n",
    "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter  # epoch counter\n",
    "    limit: !ref <number_of_epochs>\n",
    "batch_size_exponent: 4 # @orion_step1: --batch_size_exponent~\"uniform(4, 6,discrete=True)\"\n",
    "batch_size: !ref 2 ** <batch_size_exponent>\n",
    "valid_ratio: 0.2\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "# cutcat (disabled when min_num_segments=max_num_segments=1)\n",
    "max_num_segments: 3 # @orion_step2: --max_num_segments~\"uniform(2, 6, discrete=True)\"\n",
    "cutcat: !new:speechbrain.augment.time_domain.CutCat\n",
    "    min_num_segments: 2\n",
    "    max_num_segments: !ref <max_num_segments>\n",
    "# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)\n",
    "amp_delta: 0.01742 # @orion_step2: --amp_delta~\"uniform(0.0, 0.5)\"\n",
    "rand_amp: !new:speechbrain.augment.time_domain.RandAmp\n",
    "    amp_low: !ref 1 - <amp_delta>\n",
    "    amp_high: !ref 1 + <amp_delta>\n",
    "# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)\n",
    "shift_delta_: 1 # orion_step2: --shift_delta_~\"uniform(0, 25, discrete=True)\"\n",
    "shift_delta: !ref 1e-2 * <shift_delta_> # 0.250 # 0.-0.25 with steps of 0.01\n",
    "min_shift: !apply:math.floor\n",
    "    - !ref 0 - <sample_rate> * <shift_delta>\n",
    "max_shift: !apply:math.floor\n",
    "    - !ref 0 + <sample_rate> * <shift_delta>\n",
    "time_shift: !new:speechbrain.augment.freq_domain.RandomShift\n",
    "    min_shift: !ref <min_shift>\n",
    "    max_shift: !ref <max_shift>\n",
    "    dim: 1\n",
    "# injection of gaussian white noise\n",
    "snr_white_low: 15.0 # @orion_step2: --snr_white_low~\"uniform(0.0, 15, precision=2)\"\n",
    "snr_white_delta: 19.1 # @orion_step2: --snr_white_delta~\"uniform(5.0, 20.0, precision=3)\"\n",
    "snr_white_high: !ref <snr_white_low> + <snr_white_delta>\n",
    "add_noise_white: !new:speechbrain.augment.time_domain.AddNoise\n",
    "    snr_low: !ref <snr_white_low>\n",
    "    snr_high: !ref <snr_white_high>\n",
    "\n",
    "repeat_augment: 1 # @orion_step1: --repeat_augment 0\n",
    "augment: !new:speechbrain.augment.augmenter.Augmenter\n",
    "    parallel_augment: True\n",
    "    concat_original: True\n",
    "    parallel_augment_fixed_bs: True\n",
    "    repeat_augment: !ref <repeat_augment>\n",
    "    shuffle_augmentations: True\n",
    "    min_augmentations: 4\n",
    "    max_augmentations: 4\n",
    "    augmentations: [\n",
    "        !ref <cutcat>,\n",
    "        !ref <rand_amp>,\n",
    "        !ref <time_shift>,\n",
    "        !ref <add_noise_white>]\n",
    "\n",
    "# DATA NORMALIZATION\n",
    "dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)\n",
    "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
    "    dims: !ref <dims_to_normalize>\n",
    "# MODEL\n",
    "input_shape: [null, !ref <T>, !ref <C>, null]\n",
    "cnn_temporal_kernels: 61 # @orion_step1: --cnn_temporal_kernels~\"uniform(4, 64,discrete=True)\"\n",
    "cnn_temporal_kernelsize: 51 # @orion_step1: --cnn_temporal_kernelsize~\"uniform(24, 62,discrete=True)\"\n",
    "# depth multiplier for the spatial depthwise conv. layer\n",
    "cnn_spatial_depth_multiplier: 4 # @orion_step1: --cnn_spatial_depth_multiplier~\"uniform(1, 4,discrete=True)\"\n",
    "cnn_spatial_max_norm: 1.  # kernel max-norm constaint of the spatial depthwise conv. layer\n",
    "cnn_spatial_pool: 4\n",
    "cnn_septemporal_depth_multiplier: 1  # depth multiplier for the separable temporal conv. layer\n",
    "cnn_septemporal_point_kernels_ratio_: 7 # @orion_step1: --cnn_septemporal_point_kernels_ratio_~\"uniform(0, 8, discrete=True)\"\n",
    "cnn_septemporal_point_kernels_ratio: !ref <cnn_septemporal_point_kernels_ratio_> / 4\n",
    "## number of temporal filters in the separable temporal conv. layer\n",
    "cnn_septemporal_point_kernels_: !ref <cnn_temporal_kernels> * <cnn_spatial_depth_multiplier> * <cnn_septemporal_depth_multiplier>\n",
    "cnn_septemporal_point_kernels: !apply:math.ceil\n",
    "    - !ref <cnn_septemporal_point_kernels_ratio> * <cnn_septemporal_point_kernels_> + 1\n",
    "cnn_septemporal_kernelsize_: 15 # @orion_step1: --cnn_septemporal_kernelsize_~\"uniform(3, 24,discrete=True)\"\n",
    "max_cnn_spatial_pool: 4\n",
    "cnn_septemporal_kernelsize: !apply:round\n",
    "    - !ref <cnn_septemporal_kernelsize_> * <max_cnn_spatial_pool> / <cnn_spatial_pool>\n",
    "cnn_septemporal_pool: 7 # @orion_step1: --cnn_septemporal_pool~\"uniform(1, 8,discrete=True)\"\n",
    "cnn_pool_type: 'avg'\n",
    "dense_max_norm: 0.25  # kernel max-norm constaint of the dense layer\n",
    "dropout: 0.008464 # @orion_step1: --dropout~\"uniform(0.0, 0.5)\"\n",
    "activation_type: 'elu'\n",
    "\n",
    "model: !new:models.EEGNet.EEGNet\n",
    "    input_shape: !ref <input_shape>\n",
    "    cnn_temporal_kernels: !ref <cnn_temporal_kernels>\n",
    "    cnn_temporal_kernelsize: [!ref <cnn_temporal_kernelsize>, 1]\n",
    "    cnn_spatial_depth_multiplier: !ref <cnn_spatial_depth_multiplier>\n",
    "    cnn_spatial_max_norm: !ref <cnn_spatial_max_norm>\n",
    "    cnn_spatial_pool: [!ref <cnn_spatial_pool>, 1]\n",
    "    cnn_septemporal_depth_multiplier: !ref <cnn_septemporal_depth_multiplier>\n",
    "    cnn_septemporal_point_kernels: !ref <cnn_septemporal_point_kernels>\n",
    "    cnn_septemporal_kernelsize: [!ref <cnn_septemporal_kernelsize>, 1]\n",
    "    cnn_septemporal_pool: [!ref <cnn_septemporal_pool>, 1]\n",
    "    cnn_pool_type: !ref <cnn_pool_type>\n",
    "    activation_type: !ref <activation_type>\n",
    "    dense_max_norm: !ref <dense_max_norm>\n",
    "    dropout: !ref <dropout>\n",
    "    dense_n_neurons: !ref <n_classes>\n",
    "\n",
    "\n",
    "# MODEL\n",
    "# input_shape: [null, !ref <T>, !ref <C>, null]\n",
    "\n",
    "# model: !new:models.MyModel.MyModel\n",
    "#     input_shape: !ref <input_shape>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the yaml file on disk\n",
    "f = open('hyperparams.yaml', \"w\")\n",
    "f.write(example_hyperparams)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aquan/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md               \u001b[0m\u001b[01;34mhparams\u001b[0m/  \u001b[01;32mrun_experiments.sh\u001b[0m*          train.py\n",
      "\u001b[01;34mdata\u001b[0m/                   \u001b[01;34mmodels\u001b[0m/   \u001b[01;32mrun_hparam_optimization.sh\u001b[0m*  \u001b[01;34mutils\u001b[0m/\n",
      "extra-requirements.txt  \u001b[01;34mresults\u001b[0m/  \u001b[01;35mspeechbrain-moabb_logo.svg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network on a single cross-validation fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aquan/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n",
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "torchvision is not available - cannot save figures\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "Prepare dataset iterators...\n",
      "data/BNCI2014001\n",
      "Choosing from all possible events\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file '/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB/data/BNCI2014001/MNE-bnci-data/database/data-sets/001-2014/A01T.mat'.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 237GB/s]\n",
      "SHA256 hash of downloaded file: 054f02e70cf9c4ada1517e9b9864f45407939c1062c6793516585c6f511d0325\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat' to file '/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB/data/BNCI2014001/MNE-bnci-data/database/data-sets/001-2014/A01E.mat'.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 43.8M/43.8M [00:00<00:00, 408GB/s]\n",
      "SHA256 hash of downloaded file: 53d415f39c3d7b0c88b894d7b08d99bcdfe855ede63831d3691af1a45607fb62\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Saving the dataset at data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
      "Session/sessions used as training and validation set: ['0train']\n",
      "Session used as test set: ['1test']\n",
      "Validation indices: [3, 16, 38, 58, 79, 110, 130, 152, 176, 197, 223, 240, 270, 287, 2, 20, 42, 72, 90, 112, 129, 156, 170, 201, 210, 242, 257, 286, 1, 33, 43, 62, 80, 111, 137, 150, 177, 199, 230, 245, 262, 284, 0, 25, 39, 66, 86, 107, 119, 157, 173, 196, 214, 241, 250, 276]\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test\n",
      "__main__ - Experiment directory: results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test\n",
      "__main__ - Input shape: torch.Size([500, 17, 1])\n",
      "__main__ - Training set avg value: 4.9769884213901605e-08\n",
      "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "speechbrain.core - MOABBBrain Model Statistics:\n",
      "* Total Number of Trainable Parameters: 145.9k\n",
      "* Total Number of Parameters: 145.9k\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EEGNet                                   [1, 4]                    --\n",
      "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
      "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
      "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
      "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
      "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
      "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
      "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
      "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
      "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
      "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
      "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
      "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
      "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
      "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
      "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
      "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
      "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
      "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
      "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
      "├─Sequential: 1-2                        [1, 4]                    --\n",
      "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
      "│    └─Linear: 2-15                      [1, 4]                    --\n",
      "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
      "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
      "==========================================================================================\n",
      "Total params: 145,925\n",
      "Trainable params: 145,925\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 42.06\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 11.35\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 11.97\n",
      "==========================================================================================\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 1, lr: 1.95e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.89e-01, valid acc: 3.04e-01, valid cm: [[ 0 14  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 13  0  1]\n",
      " [ 0 11  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 2\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 2, lr: 4.03e-05 - train loss: 1.35 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0 14  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 14  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 3\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 3, lr: 6.11e-05 - train loss: 1.27 - valid loss: 1.39, valid f1: 1.90e-01, valid acc: 2.86e-01, valid cm: [[ 0 14  0  0]\n",
      " [ 1 13  0  0]\n",
      " [ 2 11  0  1]\n",
      " [ 2  9  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 4\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 4, lr: 8.19e-05 - train loss: 1.19 - valid loss: 1.39, valid f1: 1.39e-01, valid acc: 2.68e-01, valid cm: [[ 0 14  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 13  1  0]\n",
      " [ 3 11  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 5\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 5, lr: 9.72e-05 - train loss: 1.09 - valid loss: 1.39, valid f1: 2.16e-01, valid acc: 3.21e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 8  6  0  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 6\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 6, lr: 7.64e-05 - train loss: 9.97e-01 - valid loss: 1.39, valid f1: 2.19e-01, valid acc: 3.21e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 7\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 7, lr: 5.56e-05 - train loss: 9.33e-01 - valid loss: 1.39, valid f1: 2.19e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [10  4  0  0]\n",
      " [12  2  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 8\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 8, lr: 3.47e-05 - train loss: 8.73e-01 - valid loss: 1.39, valid f1: 2.23e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 9\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 9, lr: 1.39e-05 - train loss: 8.50e-01 - valid loss: 1.39, valid f1: 2.23e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 10\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 9.7e-06\n",
      "speechbrain.utils.train_logger - epoch: 10, lr: 6.95e-06 - train loss: 8.20e-01 - valid loss: 1.39, valid f1: 2.23e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 11\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 3.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 11, lr: 2.78e-05 - train loss: 8.23e-01 - valid loss: 1.39, valid f1: 2.21e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [10  4  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 12\n",
      "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 5.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 12, lr: 4.86e-05 - train loss: 8.05e-01 - valid loss: 1.39, valid f1: 2.23e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 13\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 7.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 13, lr: 6.94e-05 - train loss: 7.78e-01 - valid loss: 1.39, valid f1: 2.13e-01, valid acc: 3.04e-01, valid cm: [[11  3  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 14\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 14, lr: 9.03e-05 - train loss: 7.16e-01 - valid loss: 1.39, valid f1: 1.99e-01, valid acc: 2.86e-01, valid cm: [[11  3  0  0]\n",
      " [ 9  5  0  0]\n",
      " [13  1  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 15\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 15, lr: 8.89e-05 - train loss: 6.65e-01 - valid loss: 1.39, valid f1: 2.13e-01, valid acc: 3.04e-01, valid cm: [[11  3  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 16\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 16, lr: 6.81e-05 - train loss: 6.28e-01 - valid loss: 1.39, valid f1: 1.99e-01, valid acc: 2.86e-01, valid cm: [[11  3  0  0]\n",
      " [ 9  5  0  0]\n",
      " [13  1  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 17\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 17, lr: 4.72e-05 - train loss: 5.70e-01 - valid loss: 1.39, valid f1: 2.13e-01, valid acc: 3.04e-01, valid cm: [[11  3  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 18\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 18, lr: 2.64e-05 - train loss: 5.48e-01 - valid loss: 1.39, valid f1: 2.29e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [12  2  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 19\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 2.8e-06\n",
      "speechbrain.utils.train_logger - epoch: 19, lr: 5.56e-06 - train loss: 5.26e-01 - valid loss: 1.39, valid f1: 2.29e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [12  2  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 20\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 20, lr: 1.53e-05 - train loss: 5.34e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  3  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 21\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 21, lr: 3.61e-05 - train loss: 5.26e-01 - valid loss: 1.39, valid f1: 2.64e-01, valid acc: 3.39e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  2  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 22\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 6e-05\n",
      "speechbrain.utils.train_logger - epoch: 22, lr: 5.69e-05 - train loss: 5.10e-01 - valid loss: 1.39, valid f1: 2.64e-01, valid acc: 3.39e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  2  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 23\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 8.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 23, lr: 7.78e-05 - train loss: 5.03e-01 - valid loss: 1.39, valid f1: 2.64e-01, valid acc: 3.39e-01, valid cm: [[11  3  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  2  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 24\n",
      "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 24, lr: 9.86e-05 - train loss: 4.71e-01 - valid loss: 1.41, valid f1: 2.52e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  2  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 25\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 7.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 25, lr: 8.06e-05 - train loss: 4.17e-01 - valid loss: 1.41, valid f1: 2.52e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
      " [ 7  7  0  0]\n",
      " [11  2  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 26\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 5.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 26, lr: 5.97e-05 - train loss: 4.00e-01 - valid loss: 1.41, valid f1: 2.47e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
      " [ 7  7  0  0]\n",
      " [ 9  4  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 27\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 27, lr: 3.89e-05 - train loss: 3.80e-01 - valid loss: 1.42, valid f1: 2.75e-01, valid acc: 3.57e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 9  4  1  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 28\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 28, lr: 1.81e-05 - train loss: 3.63e-01 - valid loss: 1.42, valid f1: 3.04e-01, valid acc: 3.75e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  4  2  0]\n",
      " [13  0  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 29\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 5.6e-06\n",
      "speechbrain.utils.train_logger - epoch: 29, lr: 2.79e-06 - train loss: 3.69e-01 - valid loss: 1.41, valid f1: 3.01e-01, valid acc: 3.75e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  4  2  0]\n",
      " [12  1  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 30\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 30, lr: 2.36e-05 - train loss: 3.59e-01 - valid loss: 1.41, valid f1: 3.31e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 7  4  3  0]\n",
      " [13  0  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 31\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 31, lr: 4.45e-05 - train loss: 3.58e-01 - valid loss: 1.40, valid f1: 3.28e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 7  4  3  0]\n",
      " [12  1  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 32\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 32, lr: 6.53e-05 - train loss: 3.46e-01 - valid loss: 1.39, valid f1: 3.28e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 7  4  3  0]\n",
      " [12  1  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 33\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 33, lr: 8.61e-05 - train loss: 3.29e-01 - valid loss: 1.38, valid f1: 3.26e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 7  4  3  0]\n",
      " [11  2  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 34\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9e-05\n",
      "speechbrain.utils.train_logger - epoch: 34, lr: 9.31e-05 - train loss: 3.26e-01 - valid loss: 1.36, valid f1: 3.52e-01, valid acc: 4.11e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 6  4  4  0]\n",
      " [12  1  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 35\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 6.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 35, lr: 7.22e-05 - train loss: 3.15e-01 - valid loss: 1.33, valid f1: 3.52e-01, valid acc: 4.11e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 7  3  4  0]\n",
      " [11  2  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 36\n",
      "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 4.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 36, lr: 5.14e-05 - train loss: 2.90e-01 - valid loss: 1.31, valid f1: 3.50e-01, valid acc: 4.11e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 6  4  4  0]\n",
      " [11  2  1  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 37\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 2.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 37, lr: 3.06e-05 - train loss: 2.83e-01 - valid loss: 1.27, valid f1: 3.89e-01, valid acc: 4.46e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 5  3  6  0]\n",
      " [10  1  3  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 38\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 7e-06\n",
      "speechbrain.utils.train_logger - epoch: 38, lr: 9.73e-06 - train loss: 2.67e-01 - valid loss: 1.23, valid f1: 4.07e-01, valid acc: 4.64e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 4  3  7  0]\n",
      " [10  1  3  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 39\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 39, lr: 1.11e-05 - train loss: 2.47e-01 - valid loss: 1.18, valid f1: 4.75e-01, valid acc: 5.00e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 4  3  7  0]\n",
      " [ 8  1  3  2]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 40\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 40, lr: 3.20e-05 - train loss: 2.63e-01 - valid loss: 1.13, valid f1: 5.32e-01, valid acc: 5.36e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 4  3  7  0]\n",
      " [ 7  0  3  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 41\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 41, lr: 5.28e-05 - train loss: 2.70e-01 - valid loss: 1.08, valid f1: 5.49e-01, valid acc: 5.54e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 3  3  8  0]\n",
      " [ 7  0  3  4]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-13+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 42\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 42, lr: 7.36e-05 - train loss: 2.59e-01 - valid loss: 1.01, valid f1: 6.12e-01, valid acc: 6.07e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 2  3  9  0]\n",
      " [ 5  0  3  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-18+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 43\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 43, lr: 9.44e-05 - train loss: 2.42e-01 - valid loss: 9.69e-01, valid f1: 6.32e-01, valid acc: 6.25e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  4  9  0]\n",
      " [ 4  0  3  7]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-23+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 44\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 44, lr: 8.47e-05 - train loss: 2.45e-01 - valid loss: 9.05e-01, valid f1: 6.30e-01, valid acc: 6.25e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  4  9  0]\n",
      " [ 3  0  4  7]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-28+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 45\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 45, lr: 6.39e-05 - train loss: 2.14e-01 - valid loss: 8.78e-01, valid f1: 6.50e-01, valid acc: 6.43e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  4  9  0]\n",
      " [ 2  0  4  8]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-33+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 46\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4e-05\n",
      "speechbrain.utils.train_logger - epoch: 46, lr: 4.31e-05 - train loss: 2.27e-01 - valid loss: 8.44e-01, valid f1: 6.47e-01, valid acc: 6.43e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  3  9  1]\n",
      " [ 2  0  4  8]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-38+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 47\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 1.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 47, lr: 2.22e-05 - train loss: 2.15e-01 - valid loss: 8.04e-01, valid f1: 6.81e-01, valid acc: 6.79e-01, valid cm: [[10  4  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  2  9  2]\n",
      " [ 2  0  3  9]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-43+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 48\n",
      "speechbrain.nnet.schedulers - Changing lr from 1e-08 to 1.4e-06\n",
      "speechbrain.utils.train_logger - epoch: 48, lr: 1.40e-06 - train loss: 2.09e-01 - valid loss: 7.78e-01, valid f1: 6.80e-01, valid acc: 6.79e-01, valid cm: [[10  4  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  2  9  2]\n",
      " [ 1  0  4  9]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-47+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 49\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 49, lr: 1.95e-05 - train loss: 1.88e-01 - valid loss: 7.55e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  2  9  2]\n",
      " [ 1  0  3 10]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-52+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 50\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 50, lr: 4.03e-05 - train loss: 1.94e-01 - valid loss: 7.26e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  2  9  2]\n",
      " [ 1  0  3 10]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-57+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-57+00\n",
      "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 8.98e-01, test f1: 6.15e-01, test acc: 6.15e-01, test cm: [[42 24  3  3]\n",
      " [12 60  0  0]\n",
      " [21 12 37  2]\n",
      " [13  6 15 38]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-58+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-43+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-23+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-18+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-33+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-57+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-52+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-13+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-38+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-28+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-47+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-03-27+10-55-58+00\n",
      "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 1.60e-01, test f1: 6.32e-01, test acc: 6.25e-01, test cm: [[ 9  5  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 1  4  9  0]\n",
      " [ 4  0  3  7]]\n"
     ]
    }
   ],
   "source": [
    "%cd ./benchmarks/benchmarks/MOABB/\n",
    "\n",
    "!python train.py ../../../hyperparams.yaml\\\n",
    "--data_folder 'data/BNCI2014001' \\\n",
    "--cached_data_folder 'data/' \\\n",
    "--output_folder 'results/single-fold-example/BNCI2014001' \\\n",
    "--data_iterator_name 'leave-one-session-out' \\\n",
    "--target_subject_idx 0 \\\n",
    "--target_session_idx 1 \\\n",
    "--number_of_epochs 50 \\\n",
    "--device 'cpu' # Switch to cuda for a speed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a complete experiment by looping over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams: ../../../hyperparams.yaml\n",
      "data_folder: data/BNCI2014001\n",
      "cached_data_folder: data/\n",
      "output_folder: results/full-experiment/BNCI2014001\n",
      "nsbj: 9\n",
      "nsess: 2\n",
      "seed: 17449\n",
      "nruns: 2\n",
      "eval_metric: acc\n",
      "eval_set: test\n",
      "train_mode: leave-one-session-out\n",
      "rnd_dir: False\n",
      "additional flags: --number_of_epochs 50 --device cpu \n",
      "Subject 0\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n",
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "torchvision is not available - cannot save figures\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "Prepare dataset iterators...\n",
      "Using cached dataset at: data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
      "Skipping data saving, a cached dataset was found at data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
      "Session/sessions used as training and validation set: ['1test']\n",
      "Session used as test set: ['0train']\n",
      "Validation indices: [288, 307, 320, 348, 367, 390, 412, 439, 463, 482, 510, 529, 557, 574, 289, 300, 324, 351, 376, 406, 423, 445, 461, 485, 505, 531, 545, 568, 295, 316, 330, 359, 377, 396, 414, 440, 470, 484, 508, 528, 565, 575, 297, 306, 334, 358, 372, 401, 418, 442, 454, 489, 503, 530, 549, 572]\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train\n",
      "__main__ - Experiment directory: results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train\n",
      "__main__ - Input shape: torch.Size([500, 17, 1])\n",
      "__main__ - Training set avg value: 1.095636861236926e-07\n",
      "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "speechbrain.core - MOABBBrain Model Statistics:\n",
      "* Total Number of Trainable Parameters: 145.9k\n",
      "* Total Number of Parameters: 145.9k\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EEGNet                                   [1, 4]                    --\n",
      "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
      "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
      "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
      "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
      "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
      "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
      "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
      "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
      "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
      "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
      "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
      "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
      "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
      "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
      "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
      "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
      "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
      "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
      "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
      "├─Sequential: 1-2                        [1, 4]                    --\n",
      "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
      "│    └─Linear: 2-15                      [1, 4]                    --\n",
      "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
      "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
      "==========================================================================================\n",
      "Total params: 145,925\n",
      "Trainable params: 145,925\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 42.06\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 11.35\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 11.97\n",
      "==========================================================================================\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 1, lr: 1.95e-05 - train loss: 1.41 - valid loss: 1.39, valid f1: 1.99e-01, valid acc: 2.68e-01, valid cm: [[ 2  0  0 12]\n",
      " [ 4  0  0 10]\n",
      " [ 0  0  2 12]\n",
      " [ 3  0  0 11]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 2\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 2, lr: 4.03e-05 - train loss: 1.35 - valid loss: 1.39, valid f1: 1.74e-01, valid acc: 2.68e-01, valid cm: [[ 5  0  0  9]\n",
      " [ 6  0  0  8]\n",
      " [ 4  0  0 10]\n",
      " [ 4  0  0 10]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 3\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 3, lr: 6.11e-05 - train loss: 1.26 - valid loss: 1.39, valid f1: 1.97e-01, valid acc: 2.68e-01, valid cm: [[10  0  0  4]\n",
      " [12  1  0  1]\n",
      " [10  0  0  4]\n",
      " [10  0  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 4\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 4, lr: 8.19e-05 - train loss: 1.18 - valid loss: 1.39, valid f1: 1.38e-01, valid acc: 2.14e-01, valid cm: [[10  1  0  3]\n",
      " [12  1  0  1]\n",
      " [10  0  0  4]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 5\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 5, lr: 9.72e-05 - train loss: 1.08 - valid loss: 1.39, valid f1: 1.07e-01, valid acc: 1.96e-01, valid cm: [[10  2  0  2]\n",
      " [13  1  0  0]\n",
      " [12  1  0  1]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 6\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 6, lr: 7.64e-05 - train loss: 1.00 - valid loss: 1.39, valid f1: 1.59e-01, valid acc: 2.50e-01, valid cm: [[11  3  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 7\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 7, lr: 5.56e-05 - train loss: 9.27e-01 - valid loss: 1.39, valid f1: 1.54e-01, valid acc: 2.68e-01, valid cm: [[13  1  0  0]\n",
      " [12  2  0  0]\n",
      " [13  1  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 8\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 8, lr: 3.47e-05 - train loss: 8.70e-01 - valid loss: 1.39, valid f1: 1.36e-01, valid acc: 2.32e-01, valid cm: [[11  3  0  0]\n",
      " [12  2  0  0]\n",
      " [13  1  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 9\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 9, lr: 1.39e-05 - train loss: 8.27e-01 - valid loss: 1.39, valid f1: 1.57e-01, valid acc: 2.50e-01, valid cm: [[11  3  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 10\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 9.7e-06\n",
      "speechbrain.utils.train_logger - epoch: 10, lr: 6.95e-06 - train loss: 8.14e-01 - valid loss: 1.39, valid f1: 1.77e-01, valid acc: 2.68e-01, valid cm: [[11  3  0  0]\n",
      " [10  4  0  0]\n",
      " [13  1  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 11\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 3.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 11, lr: 2.78e-05 - train loss: 7.93e-01 - valid loss: 1.38, valid f1: 1.82e-01, valid acc: 2.68e-01, valid cm: [[10  4  0  0]\n",
      " [ 9  5  0  0]\n",
      " [12  2  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 12\n",
      "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 5.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 12, lr: 4.86e-05 - train loss: 8.11e-01 - valid loss: 1.38, valid f1: 1.99e-01, valid acc: 2.86e-01, valid cm: [[10  4  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 13\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 7.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 13, lr: 6.94e-05 - train loss: 7.53e-01 - valid loss: 1.38, valid f1: 1.88e-01, valid acc: 2.68e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 8  6  0  0]\n",
      " [12  2  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 14\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 14, lr: 9.03e-05 - train loss: 7.36e-01 - valid loss: 1.38, valid f1: 2.00e-01, valid acc: 2.86e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 6  8  0  0]\n",
      " [10  4  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 15\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 15, lr: 8.89e-05 - train loss: 6.77e-01 - valid loss: 1.38, valid f1: 2.08e-01, valid acc: 3.04e-01, valid cm: [[11  3  0  0]\n",
      " [ 8  6  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 16\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 16, lr: 6.81e-05 - train loss: 6.38e-01 - valid loss: 1.38, valid f1: 2.14e-01, valid acc: 3.04e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 6  8  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 17\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 17, lr: 4.72e-05 - train loss: 6.05e-01 - valid loss: 1.38, valid f1: 2.12e-01, valid acc: 3.04e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 6  8  0  0]\n",
      " [10  4  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 18\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 18, lr: 2.64e-05 - train loss: 5.68e-01 - valid loss: 1.38, valid f1: 2.14e-01, valid acc: 3.04e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 6  8  0  0]\n",
      " [11  3  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 19\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 2.8e-06\n",
      "speechbrain.utils.train_logger - epoch: 19, lr: 5.56e-06 - train loss: 5.45e-01 - valid loss: 1.38, valid f1: 2.12e-01, valid acc: 3.04e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 6  8  0  0]\n",
      " [10  4  0  0]\n",
      " [13  1  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 20\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 20, lr: 1.53e-05 - train loss: 5.51e-01 - valid loss: 1.38, valid f1: 2.63e-01, valid acc: 3.21e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 6  8  0  0]\n",
      " [ 8  4  2  0]\n",
      " [12  2  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 21\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 21, lr: 3.61e-05 - train loss: 5.33e-01 - valid loss: 1.38, valid f1: 2.73e-01, valid acc: 3.39e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  4  2  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 22\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 6e-05\n",
      "speechbrain.utils.train_logger - epoch: 22, lr: 5.69e-05 - train loss: 5.21e-01 - valid loss: 1.38, valid f1: 2.60e-01, valid acc: 3.21e-01, valid cm: [[ 7  7  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  4  2  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 23\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 8.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 23, lr: 7.78e-05 - train loss: 4.98e-01 - valid loss: 1.38, valid f1: 2.53e-01, valid acc: 3.39e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  5  1  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 24\n",
      "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 24, lr: 9.86e-05 - train loss: 4.91e-01 - valid loss: 1.38, valid f1: 2.54e-01, valid acc: 3.39e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 9  4  1  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 25\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 7.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 25, lr: 8.06e-05 - train loss: 4.60e-01 - valid loss: 1.39, valid f1: 2.51e-01, valid acc: 3.39e-01, valid cm: [[9 5 0 0]\n",
      " [5 9 0 0]\n",
      " [7 6 1 0]\n",
      " [9 5 0 0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 26\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 5.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 26, lr: 5.97e-05 - train loss: 4.26e-01 - valid loss: 1.39, valid f1: 2.41e-01, valid acc: 3.21e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 8  5  1  0]\n",
      " [10  4  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 27\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 27, lr: 3.89e-05 - train loss: 4.12e-01 - valid loss: 1.40, valid f1: 2.39e-01, valid acc: 3.21e-01, valid cm: [[8 6 0 0]\n",
      " [5 9 0 0]\n",
      " [7 6 1 0]\n",
      " [9 5 0 0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 28\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 28, lr: 1.81e-05 - train loss: 3.82e-01 - valid loss: 1.40, valid f1: 2.38e-01, valid acc: 3.21e-01, valid cm: [[8 6 0 0]\n",
      " [5 9 0 0]\n",
      " [7 6 1 0]\n",
      " [8 6 0 0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 29\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 5.6e-06\n",
      "speechbrain.utils.train_logger - epoch: 29, lr: 2.79e-06 - train loss: 3.70e-01 - valid loss: 1.40, valid f1: 2.50e-01, valid acc: 3.39e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 6  7  1  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 30\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 30, lr: 2.36e-05 - train loss: 3.83e-01 - valid loss: 1.40, valid f1: 2.50e-01, valid acc: 3.39e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 6  7  1  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 31\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 31, lr: 4.45e-05 - train loss: 3.64e-01 - valid loss: 1.40, valid f1: 2.82e-01, valid acc: 3.57e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 7  5  2  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 32\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 32, lr: 6.53e-05 - train loss: 3.71e-01 - valid loss: 1.40, valid f1: 3.12e-01, valid acc: 3.75e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 8  3  3  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 33\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 33, lr: 8.61e-05 - train loss: 3.55e-01 - valid loss: 1.42, valid f1: 2.61e-01, valid acc: 3.57e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  6  1  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 34\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9e-05\n",
      "speechbrain.utils.train_logger - epoch: 34, lr: 9.31e-05 - train loss: 3.47e-01 - valid loss: 1.41, valid f1: 2.93e-01, valid acc: 3.75e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  5  2  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 35\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 6.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 35, lr: 7.22e-05 - train loss: 3.13e-01 - valid loss: 1.39, valid f1: 3.22e-01, valid acc: 3.93e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  4  3  0]\n",
      " [ 8  6  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 36\n",
      "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 4.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 36, lr: 5.14e-05 - train loss: 3.08e-01 - valid loss: 1.37, valid f1: 3.59e-01, valid acc: 4.11e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 8  3  3  0]\n",
      " [ 7  6  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 37\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 2.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 37, lr: 3.06e-05 - train loss: 2.82e-01 - valid loss: 1.36, valid f1: 3.58e-01, valid acc: 4.11e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  4  3  0]\n",
      " [ 7  6  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 38\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 7e-06\n",
      "speechbrain.utils.train_logger - epoch: 38, lr: 9.73e-06 - train loss: 2.77e-01 - valid loss: 1.34, valid f1: 3.90e-01, valid acc: 4.29e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  4  3  0]\n",
      " [ 6  6  0  2]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 39\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 39, lr: 1.11e-05 - train loss: 2.68e-01 - valid loss: 1.31, valid f1: 4.19e-01, valid acc: 4.46e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  4  3  0]\n",
      " [ 5  6  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 40\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 40, lr: 3.20e-05 - train loss: 2.89e-01 - valid loss: 1.28, valid f1: 4.19e-01, valid acc: 4.46e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 7  4  3  0]\n",
      " [ 5  6  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 41\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 41, lr: 5.28e-05 - train loss: 2.80e-01 - valid loss: 1.23, valid f1: 4.19e-01, valid acc: 4.46e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 8  3  3  0]\n",
      " [ 5  6  0  3]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-28+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 42\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 42, lr: 7.36e-05 - train loss: 2.55e-01 - valid loss: 1.18, valid f1: 4.68e-01, valid acc: 4.82e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 6  4  4  0]\n",
      " [ 3  6  1  4]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-32+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 43\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 43, lr: 9.44e-05 - train loss: 2.68e-01 - valid loss: 1.14, valid f1: 4.78e-01, valid acc: 5.00e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 5  4  4  1]\n",
      " [ 4  5  1  4]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-37+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 44\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 44, lr: 8.47e-05 - train loss: 2.57e-01 - valid loss: 1.09, valid f1: 5.34e-01, valid acc: 5.36e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 5  3  5  1]\n",
      " [ 3  4  1  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-42+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 45\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 45, lr: 6.39e-05 - train loss: 2.32e-01 - valid loss: 1.04, valid f1: 5.30e-01, valid acc: 5.36e-01, valid cm: [[ 8  6  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 5  3  5  1]\n",
      " [ 1  4  3  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-46+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 46\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4e-05\n",
      "speechbrain.utils.train_logger - epoch: 46, lr: 4.31e-05 - train loss: 2.47e-01 - valid loss: 9.99e-01, valid f1: 5.60e-01, valid acc: 5.71e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 5  3  5  1]\n",
      " [ 1  4  3  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-51+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 47\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 1.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 47, lr: 2.22e-05 - train loss: 2.17e-01 - valid loss: 9.55e-01, valid f1: 5.81e-01, valid acc: 5.89e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 4  3  6  1]\n",
      " [ 1  4  3  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-56+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 48\n",
      "speechbrain.nnet.schedulers - Changing lr from 1e-08 to 1.4e-06\n",
      "speechbrain.utils.train_logger - epoch: 48, lr: 1.40e-06 - train loss: 2.20e-01 - valid loss: 9.27e-01, valid f1: 5.81e-01, valid acc: 5.89e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 4  3  6  1]\n",
      " [ 1  4  3  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-01+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 49\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 49, lr: 1.95e-05 - train loss: 2.14e-01 - valid loss: 8.97e-01, valid f1: 5.80e-01, valid acc: 5.89e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 4  3  6  1]\n",
      " [ 1  3  4  6]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-05+00\n",
      "speechbrain.utils.epoch_loop - Going into epoch 50\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 50, lr: 4.03e-05 - train loss: 2.15e-01 - valid loss: 8.55e-01, valid f1: 6.21e-01, valid acc: 6.25e-01, valid cm: [[ 9  5  0  0]\n",
      " [ 2 12  0  0]\n",
      " [ 4  2  7  1]\n",
      " [ 1  2  4  7]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-10+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-10+00\n",
      "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 9.81e-01, test f1: 5.77e-01, test acc: 5.76e-01, test cm: [[50 22  0  0]\n",
      " [18 53  1  0]\n",
      " [30 12 28  2]\n",
      " [18  5 14 35]]\n",
      "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-11+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-32+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-51+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-01+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-28+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-10+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-56+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-05+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-37+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-42+00\n",
      "speechbrain.utils.checkpoints - Deleted checkpoint in results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-01-46+00\n",
      "speechbrain.utils.checkpoints - Loading a checkpoint from results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-001/0train/save/CKPT+2024-03-27+11-02-11+00\n",
      "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 1.91e-01, test f1: 5.47e-01, test acc: 5.54e-01, test cm: [[ 9  5  0  0]\n",
      " [ 3 11  0  0]\n",
      " [ 5  3  5  1]\n",
      " [ 2  4  2  6]]\n",
      "Subject 1\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n",
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "torchvision is not available - cannot save figures\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "Prepare dataset iterators...\n",
      "Choosing from all possible events\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat' to file '/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB/data/BNCI2014001/MNE-bnci-data/database/data-sets/001-2014/A02T.mat'.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 43.1M/43.1M [00:00<00:00, 190GB/s]\n",
      "SHA256 hash of downloaded file: 5ddd5cb520b1692c3ba1363f48d98f58f0e46f3699ee50d749947950fc39db27\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat' to file '/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks/MOABB/data/BNCI2014001/MNE-bnci-data/database/data-sets/001-2014/A02E.mat'.\n",
      "/home/aquan/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 44.2M/44.2M [00:00<00:00, 308GB/s]\n",
      "SHA256 hash of downloaded file: d63c454005d3a9b41d8440629482e855afc823339bdd0b5721842a7ee9cc7b12\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Saving the dataset at data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-002.pkl\n",
      "Session/sessions used as training and validation set: ['1test']\n",
      "Session used as test set: ['0train']\n",
      "Validation indices: [288, 307, 320, 348, 367, 390, 412, 439, 463, 482, 510, 529, 557, 574, 289, 300, 324, 351, 376, 406, 423, 445, 461, 485, 505, 531, 545, 568, 295, 316, 330, 359, 377, 396, 414, 440, 470, 484, 508, 528, 565, 575, 297, 306, 334, 358, 372, 401, 418, 442, 454, 489, 503, 530, 549, 572]\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
      "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
      "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-002/0train\n",
      "__main__ - Experiment directory: results/full-experiment/BNCI2014001/run1/17449/leave-one-session-out/sub-002/0train\n",
      "__main__ - Input shape: torch.Size([500, 17, 1])\n",
      "__main__ - Training set avg value: -2.0912107601134267e-08\n",
      "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
      "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
      "speechbrain.core - MOABBBrain Model Statistics:\n",
      "* Total Number of Trainable Parameters: 145.9k\n",
      "* Total Number of Parameters: 145.9k\n",
      "* Trainable Parameters represent 100.0000% of the total size.\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EEGNet                                   [1, 4]                    --\n",
      "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
      "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
      "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
      "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
      "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
      "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
      "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
      "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
      "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
      "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
      "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
      "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
      "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
      "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
      "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
      "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
      "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
      "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
      "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
      "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
      "├─Sequential: 1-2                        [1, 4]                    --\n",
      "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
      "│    └─Linear: 2-15                      [1, 4]                    --\n",
      "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
      "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
      "==========================================================================================\n",
      "Total params: 145,925\n",
      "Trainable params: 145,925\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 42.06\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 11.35\n",
      "Params size (MB): 0.58\n",
      "Estimated Total Size (MB): 11.97\n",
      "==========================================================================================\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 1, lr: 1.95e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 9.42e-02, valid acc: 2.32e-01, valid cm: [[ 0  0  0 14]\n",
      " [ 0  0  0 14]\n",
      " [ 0  0  0 14]\n",
      " [ 1  0  0 13]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 2\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 2, lr: 4.03e-05 - train loss: 1.35 - valid loss: 1.39, valid f1: 9.42e-02, valid acc: 2.32e-01, valid cm: [[ 0  0  0 14]\n",
      " [ 0  0  0 14]\n",
      " [ 0  0  0 14]\n",
      " [ 1  0  0 13]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 3\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 3, lr: 6.11e-05 - train loss: 1.28 - valid loss: 1.39, valid f1: 1.79e-01, valid acc: 2.86e-01, valid cm: [[12  0  0  2]\n",
      " [12  0  0  2]\n",
      " [ 9  0  0  5]\n",
      " [10  0  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 4\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 4, lr: 8.19e-05 - train loss: 1.19 - valid loss: 1.39, valid f1: 1.80e-01, valid acc: 3.04e-01, valid cm: [[14  0  0  0]\n",
      " [12  0  0  2]\n",
      " [10  0  0  4]\n",
      " [11  0  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 5\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 5, lr: 9.72e-05 - train loss: 1.09 - valid loss: 1.39, valid f1: 1.34e-01, valid acc: 2.68e-01, valid cm: [[14  0  0  0]\n",
      " [13  0  0  1]\n",
      " [14  0  0  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 6\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 6, lr: 7.64e-05 - train loss: 1.02 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 7\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 7, lr: 5.56e-05 - train loss: 9.47e-01 - valid loss: 1.38, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 8\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 8, lr: 3.47e-05 - train loss: 8.95e-01 - valid loss: 1.38, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 9\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 9, lr: 1.39e-05 - train loss: 8.47e-01 - valid loss: 1.38, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 10\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 9.7e-06\n",
      "speechbrain.utils.train_logger - epoch: 10, lr: 6.95e-06 - train loss: 8.49e-01 - valid loss: 1.38, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 11\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 3.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 11, lr: 2.78e-05 - train loss: 8.35e-01 - valid loss: 1.38, valid f1: 1.35e-01, valid acc: 2.68e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 12\n",
      "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 5.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 12, lr: 4.86e-05 - train loss: 8.19e-01 - valid loss: 1.38, valid f1: 1.38e-01, valid acc: 2.68e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [12  2  0  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 13\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 7.2e-05\n",
      "speechbrain.utils.train_logger - epoch: 13, lr: 6.94e-05 - train loss: 8.03e-01 - valid loss: 1.38, valid f1: 2.04e-01, valid acc: 3.04e-01, valid cm: [[14  0  0  0]\n",
      " [13  1  0  0]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 14\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9.3e-05\n",
      "speechbrain.utils.train_logger - epoch: 14, lr: 9.03e-05 - train loss: 7.58e-01 - valid loss: 1.38, valid f1: 2.04e-01, valid acc: 3.04e-01, valid cm: [[14  0  0  0]\n",
      " [13  1  0  0]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 15\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 15, lr: 8.89e-05 - train loss: 7.10e-01 - valid loss: 1.38, valid f1: 1.73e-01, valid acc: 2.86e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 16\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 16, lr: 6.81e-05 - train loss: 6.53e-01 - valid loss: 1.38, valid f1: 1.71e-01, valid acc: 2.86e-01, valid cm: [[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [12  1  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 17\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 17, lr: 4.72e-05 - train loss: 6.50e-01 - valid loss: 1.37, valid f1: 2.03e-01, valid acc: 3.04e-01, valid cm: [[14  0  0  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 18\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.4e-05\n",
      "speechbrain.utils.train_logger - epoch: 18, lr: 2.64e-05 - train loss: 6.06e-01 - valid loss: 1.37, valid f1: 2.03e-01, valid acc: 3.04e-01, valid cm: [[14  0  0  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 19\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 2.8e-06\n",
      "speechbrain.utils.train_logger - epoch: 19, lr: 5.56e-06 - train loss: 5.79e-01 - valid loss: 1.37, valid f1: 1.95e-01, valid acc: 2.86e-01, valid cm: [[13  0  1  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [13  0  0  1]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 20\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 20, lr: 1.53e-05 - train loss: 6.01e-01 - valid loss: 1.37, valid f1: 2.24e-01, valid acc: 3.04e-01, valid cm: [[13  0  1  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [12  0  0  2]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 21\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 21, lr: 3.61e-05 - train loss: 5.91e-01 - valid loss: 1.36, valid f1: 2.51e-01, valid acc: 3.21e-01, valid cm: [[13  0  1  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [11  0  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 22\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 6e-05\n",
      "speechbrain.utils.train_logger - epoch: 22, lr: 5.69e-05 - train loss: 5.90e-01 - valid loss: 1.36, valid f1: 2.46e-01, valid acc: 3.21e-01, valid cm: [[13  0  1  0]\n",
      " [10  1  0  3]\n",
      " [11  2  1  0]\n",
      " [11  0  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 23\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 8.1e-05\n",
      "speechbrain.utils.train_logger - epoch: 23, lr: 7.78e-05 - train loss: 5.88e-01 - valid loss: 1.35, valid f1: 2.24e-01, valid acc: 3.04e-01, valid cm: [[13  0  1  0]\n",
      " [12  1  0  1]\n",
      " [11  2  1  0]\n",
      " [11  1  0  2]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 24\n",
      "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 24, lr: 9.86e-05 - train loss: 5.53e-01 - valid loss: 1.35, valid f1: 2.99e-01, valid acc: 3.57e-01, valid cm: [[13  0  1  0]\n",
      " [10  3  0  1]\n",
      " [10  3  1  0]\n",
      " [ 9  2  0  3]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 25\n",
      "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 7.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 25, lr: 8.06e-05 - train loss: 5.16e-01 - valid loss: 1.34, valid f1: 2.51e-01, valid acc: 3.21e-01, valid cm: [[13  0  1  0]\n",
      " [11  2  0  1]\n",
      " [11  2  1  0]\n",
      " [11  1  0  2]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 26\n",
      "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 5.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 26, lr: 5.97e-05 - train loss: 5.23e-01 - valid loss: 1.34, valid f1: 3.51e-01, valid acc: 3.93e-01, valid cm: [[13  0  1  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  4  2  0]\n",
      " [ 7  3  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 27\n",
      "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 27, lr: 3.89e-05 - train loss: 4.99e-01 - valid loss: 1.33, valid f1: 3.51e-01, valid acc: 3.93e-01, valid cm: [[13  0  1  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  4  2  0]\n",
      " [ 7  3  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 28\n",
      "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.5e-05\n",
      "speechbrain.utils.train_logger - epoch: 28, lr: 1.81e-05 - train loss: 4.82e-01 - valid loss: 1.32, valid f1: 3.41e-01, valid acc: 3.75e-01, valid cm: [[12  1  1  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  4  2  0]\n",
      " [ 7  3  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 29\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 5.6e-06\n",
      "speechbrain.utils.train_logger - epoch: 29, lr: 2.79e-06 - train loss: 4.68e-01 - valid loss: 1.32, valid f1: 3.41e-01, valid acc: 3.75e-01, valid cm: [[12  1  1  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  4  2  0]\n",
      " [ 7  3  0  4]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 30\n",
      "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.6e-05\n",
      "speechbrain.utils.train_logger - epoch: 30, lr: 2.36e-05 - train loss: 4.62e-01 - valid loss: 1.31, valid f1: 3.63e-01, valid acc: 3.93e-01, valid cm: [[12  0  2  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  4  2  0]\n",
      " [ 6  3  0  5]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 31\n",
      "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.7e-05\n",
      "speechbrain.utils.train_logger - epoch: 31, lr: 4.45e-05 - train loss: 4.58e-01 - valid loss: 1.30, valid f1: 3.88e-01, valid acc: 4.11e-01, valid cm: [[12  0  2  0]\n",
      " [ 9  3  1  1]\n",
      " [ 8  3  3  0]\n",
      " [ 6  3  0  5]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 32\n",
      "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.8e-05\n",
      "speechbrain.utils.train_logger - epoch: 32, lr: 6.53e-05 - train loss: 4.58e-01 - valid loss: 1.29, valid f1: 4.00e-01, valid acc: 4.11e-01, valid cm: [[11  1  2  0]\n",
      " [ 9  3  1  1]\n",
      " [ 7  3  4  0]\n",
      " [ 6  3  0  5]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 33\n",
      "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.9e-05\n",
      "speechbrain.utils.train_logger - epoch: 33, lr: 8.61e-05 - train loss: 4.54e-01 - valid loss: 1.29, valid f1: 4.41e-01, valid acc: 4.46e-01, valid cm: [[11  1  2  0]\n",
      " [ 8  4  1  1]\n",
      " [ 6  3  5  0]\n",
      " [ 6  3  0  5]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 34\n",
      "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9e-05\n",
      "speechbrain.utils.train_logger - epoch: 34, lr: 9.31e-05 - train loss: 4.41e-01 - valid loss: 1.29, valid f1: 4.02e-01, valid acc: 4.11e-01, valid cm: [[11  2  1  0]\n",
      " [ 9  3  1  1]\n",
      " [ 7  3  4  0]\n",
      " [ 6  3  0  5]]\n",
      "speechbrain.utils.epoch_loop - Going into epoch 35\n",
      "^C\n",
      "/home/aquan/dev/COMP432/speechbrain_moabb_project/benchmarks/benchmarks\n"
     ]
    }
   ],
   "source": [
    "!./run_experiments.sh --hparams ../../../hyperparams.yaml \\\n",
    "--data_folder 'data/BNCI2014001'\\\n",
    "--cached_data_folder 'data/' \\\n",
    "--output_folder 'results/full-experiment/BNCI2014001' \\\n",
    "--nsbj 9 --nsess 2 --nruns 2 --train_mode 'leave-one-session-out' \\\n",
    "--number_of_epochs 50 \\\n",
    "--device 'cpu'\n",
    "\n",
    "%cd .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
