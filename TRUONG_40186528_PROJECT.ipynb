{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GhrvkOFT9_t"
      },
      "source": [
        "### Download SpeechBrain-MOABB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSOTkqPsJXxZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "!pip install -r /content/benchmarks/benchmarks/MOABB/extra-requirements.txt # Install additional dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxr8nZ7bbP15"
      },
      "source": [
        "### Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFEX28mu4dFt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Clone SpeechBrain repository (development branch)\n",
        "%cd /content/\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r /content/speechbrain/requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e /content/speechbrain/.\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyyi_pEdDq-i"
      },
      "outputs": [],
      "source": [
        "%pip install -q mne moabb orion scikit-learn torch torchinfo speechbrain hyperpyyaml braindecode\n",
        "\n",
        "import mne\n",
        "import moabb\n",
        "import orion\n",
        "import sklearn\n",
        "import torch\n",
        "import torchinfo\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml, dump_hyperpyyaml\n",
        "import braindecode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt to pre-install packages"
      ],
      "metadata": {
        "id": "Qlln4zSyvSjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "wTZPK_tZo55Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install virtualenv"
      ],
      "metadata": {
        "id": "ltQVcbG2tvkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !virtualenv /content/drive/MyDrive/COMP_432/Project/colab_env"
      ],
      "metadata": {
        "id": "DzeUEM9ztyW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/drive/MyDrive/COMP_432/Project/colab_env/bin/activate; pip install mne moabb orion orion[profet] scikit-learn torch torchinfo black==24.3.0 click==8.1.7 flake8==7.0.0 pycodestyle==2.11.0 pydoclint==0.4.1 pytest==7.4.0 yamllint huggingface_hub>=0.8.0 hyperpyyaml>=0.0.1 joblib>=0.14.1 numpy>=1.17.0 packaging pandas>=1.0.1 pre-commit>=2.3.0 scipy>=1.4.1 sentencepiece>=0.1.91 torch>=1.9.0 torchaudio>=1.9.0 tqdm>=4.42.0 transformers>=4.30.0 speechbrain pygtrie>=2.1"
      ],
      "metadata": {
        "id": "ESZQyrO-scKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.append(\"/content/drive/MyDrive/COMP_432/Project/colab_env/lib/python3.10/site-packages\")"
      ],
      "metadata": {
        "id": "rrMVlCBpstLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import mne\n",
        "# import moabb\n",
        "# import orion\n",
        "# import sklearn\n",
        "# import torch\n",
        "# import torchinfo\n",
        "# import speechbrain as sb\n",
        "# import hyperpyyaml\n",
        "# from hyperpyyaml import load_hyperpyyaml, dump_hyperpyyaml"
      ],
      "metadata": {
        "id": "Hxe0z2x5rDkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !git clone https://github.com/speechbrain/benchmarks\n",
        "# %cd /content/benchmarks\n",
        "# !git checkout eeg"
      ],
      "metadata": {
        "id": "v5LJTY7xpLuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# # Clone SpeechBrain repository (development branch)\n",
        "# %cd /content/\n",
        "# !git clone https://github.com/speechbrain/speechbrain/\n",
        "\n",
        "# # # Install SpeechBrain in editable mode\n",
        "# # !pip install -e /content/speechbrain/.\n",
        "\n",
        "# %cd /content/"
      ],
      "metadata": {
        "id": "dtu9r1iOqErz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn-aaY6m23E6"
      },
      "source": [
        "### My own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBP-o2ru2qCg"
      },
      "outputs": [],
      "source": [
        "my_model = \"\"\"\n",
        "import torch\n",
        "import speechbrain as sb\n",
        "\n",
        "class DeepConvNet(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape=None, # (batch_size, time_points, channels(electrodes), num_feature_maps)\n",
        "        cnn_first_kernels=25,\n",
        "        cnn_second_kernels=25,\n",
        "        cnn_third_kernels=50,\n",
        "        cnn_fourth_kernels=100,\n",
        "        cnn_fifth_kernels=200,\n",
        "        cnn_bnorm_momentum=0.1,\n",
        "        cnn_bnorm_eps=1e-5,\n",
        "        cnn_max_norm=2,\n",
        "        cnn_kernelsize=(10, 1),\n",
        "        cnn_pool_type=\"max\",\n",
        "        cnn_pool_size=(3, 1),\n",
        "        dense_n_neurons=4,\n",
        "        dense_max_norm=0.5,\n",
        "        dropout=0.4,\n",
        "        activation_type='elu',\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if input_shape is None:\n",
        "            raise ValueError(\"Must specify input_shape\")\n",
        "        if activation_type == \"gelu\":\n",
        "            activation = torch.nn.GELU()\n",
        "        elif activation_type == \"elu\":\n",
        "            activation = torch.nn.ELU()\n",
        "        elif activation_type == \"relu\":\n",
        "            activation = torch.nn.ReLU()\n",
        "        elif activation_type == \"leaky_relu\":\n",
        "            activation = torch.nn.LeakyReLU()\n",
        "        elif activation_type == \"prelu\":\n",
        "            activation = torch.nn.PReLU()\n",
        "        else:\n",
        "            raise ValueError(\"Wrong hidden activation function\")\n",
        "        self.default_sf = 128  # sampling rate of the original publication (Hz)\n",
        "        T = input_shape[1]\n",
        "        C = input_shape[2]\n",
        "\n",
        "        #####################################################\n",
        "        # CONVOLUTIONAL MODULE\n",
        "        #####################################################\n",
        "        self.conv_module = torch.nn.Sequential()\n",
        "\n",
        "        #####################################################\n",
        "        # 1st conv layer\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_0\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=cnn_first_kernels,\n",
        "                kernel_size=cnn_kernelsize,\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        #####################################################\n",
        "        # 2nd conv layer\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_1\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_first_kernels,\n",
        "                out_channels=cnn_second_kernels,\n",
        "                kernel_size=(1, C),\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 2nd layer batchnorm\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_1\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_second_kernels,\n",
        "                momentum=cnn_bnorm_momentum,\n",
        "                eps=cnn_bnorm_eps,\n",
        "                affine=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 2nd layer activation\n",
        "        self.conv_module.add_module(\n",
        "            \"act_1\",\n",
        "            activation\n",
        "        )\n",
        "\n",
        "        # 2nd layer pooling\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_1\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_pool_size,\n",
        "                stride=cnn_pool_size,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 2nd layer dropout\n",
        "        self.conv_module.add_module(\n",
        "            \"dropout_1\",\n",
        "            torch.nn.Dropout(p=dropout),\n",
        "        )\n",
        "\n",
        "        #####################################################\n",
        "        # 3rd conv layer\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_2\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_second_kernels,\n",
        "                out_channels=cnn_third_kernels,\n",
        "                kernel_size=cnn_kernelsize,\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 3rd layer batchnorm\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_2\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_third_kernels,\n",
        "                momentum=cnn_bnorm_momentum,\n",
        "                eps=cnn_bnorm_eps,\n",
        "                affine=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 3rd layer activation\n",
        "        self.conv_module.add_module(\n",
        "            \"act_2\",\n",
        "            activation\n",
        "        )\n",
        "\n",
        "        # 3rd layer pooling\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_2\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_pool_size,\n",
        "                stride=cnn_pool_size,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 3rd layer dropout\n",
        "        self.conv_module.add_module(\n",
        "            \"dropout_2\",\n",
        "            torch.nn.Dropout(p=dropout),\n",
        "        )\n",
        "\n",
        "        #####################################################\n",
        "        # 4th conv layer\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_3\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_third_kernels,\n",
        "                out_channels=cnn_fourth_kernels,\n",
        "                kernel_size=cnn_kernelsize,\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 4th layer batchnorm\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_3\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_fourth_kernels,\n",
        "                momentum=cnn_bnorm_momentum,\n",
        "                eps=cnn_bnorm_eps,\n",
        "                affine=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 4th layer activation\n",
        "        self.conv_module.add_module(\n",
        "            \"act_3\",\n",
        "            activation\n",
        "        )\n",
        "\n",
        "        # 4th layer pooling\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_3\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_pool_size,\n",
        "                stride=cnn_pool_size,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 4th layer dropout\n",
        "        self.conv_module.add_module(\n",
        "            \"dropout_3\",\n",
        "            torch.nn.Dropout(p=dropout),\n",
        "        )\n",
        "\n",
        "        #####################################################\n",
        "        # 5th conv layer\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_4\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_fourth_kernels,\n",
        "                out_channels=cnn_fifth_kernels,\n",
        "                kernel_size=cnn_kernelsize,\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 5th layer batchnorm\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_4\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_fifth_kernels,\n",
        "                momentum=cnn_bnorm_momentum,\n",
        "                eps=cnn_bnorm_eps,\n",
        "                affine=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 5th layer activation\n",
        "        self.conv_module.add_module(\n",
        "            \"act_4\",\n",
        "            activation\n",
        "        )\n",
        "\n",
        "        # 5th layer pooling\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_4\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_pool_size,\n",
        "                stride=cnn_pool_size,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # 5th layer dropout\n",
        "        self.conv_module.add_module(\n",
        "            \"dropout_4\",\n",
        "            torch.nn.Dropout(p=dropout),\n",
        "        )\n",
        "\n",
        "        #####################################################\n",
        "        # DENSE MODULE\n",
        "        #####################################################\n",
        "        # Shape of intermediate feature map\n",
        "        current_out = self.conv_module(\n",
        "            torch.ones((1,) + tuple(input_shape[1:-1]) + (1,))\n",
        "        )\n",
        "        dense_input_size = self._num_flat_features(current_out)\n",
        "\n",
        "        self.dense_module = torch.nn.Sequential()\n",
        "\n",
        "        # flatten\n",
        "        self.dense_module.add_module(\n",
        "            \"flatten\", torch.nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # linear\n",
        "        self.dense_module.add_module(\n",
        "            \"fc_out\",\n",
        "            sb.nnet.linear.Linear(\n",
        "                input_size=dense_input_size,\n",
        "                n_neurons=dense_n_neurons,\n",
        "                max_norm=dense_max_norm,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # final activation\n",
        "        self.dense_module.add_module(\"act_out\", torch.nn.LogSoftmax(dim=1))\n",
        "\n",
        "    def _num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_module(x)\n",
        "        x = self.dense_module(x)\n",
        "        return x\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfeApsRd8DJq"
      },
      "outputs": [],
      "source": [
        "# save the model into the models folder\n",
        "f = open('/content/benchmarks/benchmarks/MOABB/models/MyModel.py', \"w\")\n",
        "f.write(my_model)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7F5CWHqf5C5"
      },
      "source": [
        "### Setting up the yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_m7D3eiUbHC"
      },
      "outputs": [],
      "source": [
        "tuned_hyperparams = \"\"\"\n",
        "# DATASET HPARS\n",
        "# band-pass filtering cut-off frequencies\n",
        "fmin: 0.13 # tuned\n",
        "fmax: 46.0 # tuned\n",
        "# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class\n",
        "# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long\n",
        "# dataset interval starts from 2\n",
        "# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)\n",
        "tmin: 0.\n",
        "tmax: 4.0 # tuned\n",
        "# number of steps used when selecting adjacent channels from a seed channel (default at Cz)\n",
        "n_steps_channel_selection: 2 # tuned\n",
        "\n",
        "# TRAINING HPARS\n",
        "# checkpoints to average\n",
        "avg_models: 10 # tuned\n",
        "number_of_epochs: 500 # @orion_step1: --number_of_epochs~\"uniform(250, 700, discrete=True)\"\n",
        "lr: 0.001 # @orion_step1: --lr~\"choices([0.01, 0.005, 0.001, 0.0005, 0.0001])\"\n",
        "batch_size_exponent: 4 # tuned\n",
        "\n",
        "# DATA AUGMENTATION\n",
        "# cutcat (disabled when min_num_segments=max_num_segments=1)\n",
        "max_num_segments: 3 # tuned\n",
        "cutcat: !new:speechbrain.augment.time_domain.CutCat\n",
        "    min_num_segments: 2\n",
        "    max_num_segments: !ref <max_num_segments>\n",
        "# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)\n",
        "amp_delta: 0.01742 # tuned\n",
        "# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)\n",
        "shift_delta_: 1 # tuned\n",
        "# injection of gaussian white noise\n",
        "snr_white_low: 15.0 # tuned\n",
        "snr_white_delta: 19.1 # tuned\n",
        "\n",
        "# MODEL\n",
        "cnn_first_kernels: 25 # @orion_step1: --cnn_first_kernels~\"uniform(4, 100,discrete=True)\"\n",
        "cnn_second_kernels: ${cnn_first_kernels}\n",
        "cnn_third_kernels: ${cnn_second_kernels * 2}\n",
        "cnn_fourth_kernels: ${cnn_third_kernels * 2}\n",
        "cnn_fifth_kernels: ${cnn_fourth_kernels * 2}\n",
        "cnn_kernelsize: 10 # @orion_step1: --cnn_kernelsize~\"uniform(5, 10,discrete=True)\"\n",
        "cnn_pool_size: 3 # @orion_step1: --cnn_pool_size~\"uniform(1, 5,discrete=True)\"\n",
        "dropout: 0.5 # @orion_step1: --dropout~\"uniform(0.0, 0.5)\"\n",
        "\"\"\"\n",
        "\n",
        "other_hyperparams = \"\"\"\n",
        "seed: 1234\n",
        "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# DIRECTORIES\n",
        "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
        "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
        "output_folder: !PLACEHOLDER #'path/to/results'\n",
        "\n",
        "# DATASET HPARS\n",
        "# Defining the MOABB dataset.\n",
        "dataset: !new:moabb.datasets.BNCI2014001\n",
        "save_prepared_dataset: True # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards\n",
        "data_iterator_name: !PLACEHOLDER\n",
        "target_subject_idx: !PLACEHOLDER\n",
        "target_session_idx: !PLACEHOLDER\n",
        "events_to_load: null # all events will be loaded\n",
        "original_sample_rate: 250 # Original sampling rate provided by dataset authors\n",
        "sample_rate: 125 # Target sampling rate (Hz)\n",
        "n_classes: 4\n",
        "T: !apply:math.ceil\n",
        "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
        "C: 22\n",
        "# We here specify how to perfom test:\n",
        "# - If test_with: 'last' we perform test with the latest model.\n",
        "# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)\n",
        "# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.\n",
        "# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.\n",
        "test_with: 'last' # 'last' or 'best'\n",
        "test_key: \"acc\" # Possible opts: \"loss\", \"f1\", \"auc\", \"acc\"\n",
        "\n",
        "# METRICS\n",
        "f1: !name:sklearn.metrics.f1_score\n",
        "    average: 'macro'\n",
        "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
        "cm: !name:sklearn.metrics.confusion_matrix\n",
        "metrics:\n",
        "    f1: !ref <f1>\n",
        "    acc: !ref <acc>\n",
        "    cm: !ref <cm>\n",
        "\n",
        "# TRAINING HPARS\n",
        "n_train_examples: 100  # it will be replaced in the train script\n",
        "# Learning rate scheduling (cyclic learning rate is used here)\n",
        "max_lr: !ref <lr> # Upper bound of the cycle (max value of the lr)\n",
        "base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)\n",
        "step_size_multiplier: 5 #from 2 to 8\n",
        "step_size: !apply:round\n",
        "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
        "    base_lr: !ref <base_lr>\n",
        "    max_lr: !ref <max_lr>\n",
        "    step_size: !ref <step_size>\n",
        "label_smoothing: 0.0\n",
        "loss: !name:speechbrain.nnet.losses.nll_loss\n",
        "    label_smoothing: !ref <label_smoothing>\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter  # epoch counter\n",
        "    limit: !ref <number_of_epochs>\n",
        "batch_size: !ref 2 ** <batch_size_exponent>\n",
        "valid_ratio: 0.2\n",
        "\n",
        "# DATA AUGMENTATION\n",
        "rand_amp: !new:speechbrain.augment.time_domain.RandAmp\n",
        "    amp_low: !ref 1 - <amp_delta>\n",
        "    amp_high: !ref 1 + <amp_delta>\n",
        "shift_delta: !ref 1e-2 * <shift_delta_> # 0.250 # 0.-0.25 with steps of 0.01\n",
        "min_shift: !apply:math.floor\n",
        "    - !ref 0 - <sample_rate> * <shift_delta>\n",
        "max_shift: !apply:math.floor\n",
        "    - !ref 0 + <sample_rate> * <shift_delta>\n",
        "time_shift: !new:speechbrain.augment.freq_domain.RandomShift\n",
        "    min_shift: !ref <min_shift>\n",
        "    max_shift: !ref <max_shift>\n",
        "    dim: 1\n",
        "snr_white_high: !ref <snr_white_low> + <snr_white_delta>\n",
        "add_noise_white: !new:speechbrain.augment.time_domain.AddNoise\n",
        "    snr_low: !ref <snr_white_low>\n",
        "    snr_high: !ref <snr_white_high>\n",
        "\n",
        "# pipeline\n",
        "repeat_augment: 2\n",
        "augment: !new:speechbrain.augment.augmenter.Augmenter\n",
        "    parallel_augment: True\n",
        "    concat_original: True\n",
        "    parallel_augment_fixed_bs: True\n",
        "    repeat_augment: !ref <repeat_augment>\n",
        "    shuffle_augmentations: True\n",
        "    min_augmentations: 4\n",
        "    max_augmentations: 4\n",
        "    augmentations: [\n",
        "        !ref <cutcat>,\n",
        "        !ref <rand_amp>,\n",
        "        !ref <time_shift>,\n",
        "        !ref <add_noise_white>]\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)\n",
        "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
        "    dims: !ref <dims_to_normalize>\n",
        "\n",
        "# MODEL\n",
        "input_shape: [null, !ref <T>, !ref <C>, null]\n",
        "cnn_bnorm_momentum: 0.1\n",
        "cnn_bnorm_eps: 1e-5\n",
        "cnn_max_norm: 2\n",
        "cnn_pool_type: \"max\"\n",
        "dense_max_norm: 0.5\n",
        "activation_type: 'elu'\n",
        "\n",
        "model: !new:models.MyModel.DeepConvNet\n",
        "    input_shape: !ref <input_shape>\n",
        "    cnn_first_kernels: !ref <cnn_first_kernels>\n",
        "    cnn_second_kernels: !ref <cnn_second_kernels>\n",
        "    cnn_third_kernels: !ref <cnn_third_kernels>\n",
        "    cnn_fourth_kernels: !ref <cnn_fourth_kernels>\n",
        "    cnn_fifth_kernels: !ref <cnn_fifth_kernels>\n",
        "    cnn_bnorm_momentum: !ref <cnn_bnorm_momentum>\n",
        "    cnn_bnorm_eps: !ref <cnn_bnorm_eps>\n",
        "    cnn_max_norm: !ref <cnn_max_norm>\n",
        "    cnn_kernelsize: [!ref <cnn_kernelsize>, 1]\n",
        "    cnn_pool_type: !ref <cnn_pool_type>\n",
        "    cnn_pool_size: [!ref <cnn_pool_size>, 1]\n",
        "    dense_max_norm: !ref <dense_max_norm>\n",
        "    dropout: !ref <dropout>\n",
        "    activation_type: !ref <activation_type>\n",
        "\n",
        "# # other models that im not using\n",
        "# model: !new:models.MyModel.EEGNetFusion\n",
        "#     input_shape: !ref <input_shape>\n",
        "# model: !new:models.MyModel.MyEEGNet\n",
        "#     input_shape: !ref <input_shape>\n",
        "\"\"\"\n",
        "\n",
        "hyperparams = tuned_hyperparams + other_hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbJcCq8fYgL-"
      },
      "outputs": [],
      "source": [
        "# Save the yaml file on disk\n",
        "f = open('/content/hyperparams.yaml', \"w\")\n",
        "f.write(hyperparams)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiOA1AlVg48b"
      },
      "source": [
        "### Train the neural network on a single cross-validation fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYEa8oubbvk-"
      },
      "outputs": [],
      "source": [
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "\n",
        "!python train.py /content/hyperparams.yaml \\\n",
        "--data_folder '/content/data/BNCI2014001' \\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/single-fold-example/BNCI2014001' \\\n",
        "--data_iterator_name 'leave-one-session-out' \\\n",
        "--target_subject_idx 0 \\\n",
        "--target_session_idx 1 \\\n",
        "--number_of_epochs 50 \\\n",
        "--device 'cuda' # Switch to cuda for a speed up.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITKUTG0JUcha"
      },
      "source": [
        "## Run a complete experiment by looping over the entire dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOD1JbH2TSZj"
      },
      "outputs": [],
      "source": [
        "!./run_experiments.sh --hparams /content/hyperparams.yaml \\\n",
        "--data_folder '/content/data/BNCI2014001'\\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/full-experiment/BNCI2014001' \\\n",
        "--nsbj 9 --nsess 2 --nruns 1 --train_mode 'leave-one-session-out' \\\n",
        "--number_of_epochs 350 \\\n",
        "--device 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "aZOTbb88gMFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "\n",
        "!./run_hparam_optimization.sh --hparams '/content/hyperparams.yaml' \\\n",
        "--data_folder '/content/data/BNCI2014001'\\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/hyperparameter-search-new/BNCI2014001' \\\n",
        "--nsbj 9 --nsess 2 --nruns 1 --train_mode 'leave-one-session-out' \\\n",
        "--exp_name 'hyperparameter-search' \\\n",
        "--nsbj_hpsearch 1 --nsess_hpsearch 1 \\\n",
        "--nruns_eval 1 \\\n",
        "--eval_metric acc \\\n",
        "--exp_max_trials 5"
      ],
      "metadata": {
        "id": "SfzqL6llgWfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Qlln4zSyvSjO",
        "qiOA1AlVg48b",
        "ITKUTG0JUcha",
        "aZOTbb88gMFL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}